process vs thread
parallelism vs concuranccy?

what are datastructures
What is big O notations?
what are arrays?
BIg O for add to start/end to array , remove from start/end from array , search an array 
array vs linkedlist
green threads
greenlets
garbage collection/
garbage collection generations


cdc - change data capture
###################################################################################################################


#####class vs object


In object-oriented terminology, 

a class is a template for defining objects. 
It specifies the names and types of variables that can exist in an object, as well as "methods"--procedures for operating on those variables. A class can be thought of as a "type", with the objects being a "variable" of that type. Multiple objects, or instances of a class can be created in a single HLU program, just as you declare multiple variables of the same type in any program.
For example, the TextItem class is a template for creating an object that contains a text string. This object will have a particular set of text attributes such as font, size, and color. If we set the values of the object variables--resources--in a certain way, we can create the TextItem object "Hello World". Resources that are available for objects of the TextItem class include the text string ("Hello World" in this case), the type of font, the color of the characters, the size of the characters, the line width of the characters, etc. A TextItem object is thus an instance of the TextItem class with a set of values assigned to the associated resources. We can create a second TextItem object if we want to with a new set of resource values such as: "THIS IS ALSO A TEXTITEM OBJECT."

Class versus object
Many people get confused by the difference between class and object. The difference is simple and conceptual. 

Class:
A class is a template for objects. A class defines object properties including a valid range of values, and a default value. A class also describes object behavior. 

Object:
An object is a member or an "instance" of a class. An object has a state in which all of its properties have values that you either explicitly define or that are defined by default settings.
This subtle conceptual difference between classes and objects shows why there is a tendency to want to use them interchangeably.



############################

Big O notation:

Big O Notation
What is the Big O Notation? Big O is the way we describe the performance efficiency or complexity of algorithms.

we must first understand Big O and some of the different time complexity possibilities. Below are three different possibilities for the speed of an algorithm.
O(1): Executes in the same time regardless of the size of the input
O(n): Executes linearly and proportionally to the size of the input
O(n²): Performance is directly proportional to the square of the size of the input (ex: nested iterations, loops)



###############################################################


##### data profiling

Data profiling is the process of examining the data available from an existing information source (e.g. a database or a file) and collecting statistics or informative summaries about that data. The purpose of these statistics may be to: Find out whether existing data can be easily used for other purposes

######################

#### process vs thread  

Process:
Process means any program is in execution. Process control block controls the operation of any process. Process control block contains the information about processes for example: Process priority, process id, process state, CPU, register etc. A process can creates other processes which are known as Child Processes. Process takes more time to terminate and it is isolated means it does not share memory with any other process.

Thread:
A thread is a basic unit of CPU utilization

Thread is the segment of a process means a process can have multiple threads and these multiple threads are contained within a process. A thread have 3 states: running, ready, and blocked.

Thread takes less time to terminate as compared to process and like process threads do not isolate.

A thread is a basic unit of CPU utilization. It is also referred to as a “lightweight process”.

A thread is a sequence of instructions within a process and it behaves like “a process within a process”. It differs from a process because it does not have its own Process Control Block (collection of information about the processes). Usually, multiple threads are created within a process. Threads execute within a process and processes execute within the operating system kernel.

A thread comprises:

thread ID
program counter
register set
stack
A thread shares resources with its peer threads (all other threads in a particular task), such as:

code section
data section
any operating resources which are available to the task



Difference between Process and Thread:

S.NO	PROCESS	THREAD
1.	Process means any program is in execution.                  	Thread means segment of a process.
2.	Process takes more time to terminate.	                        Thread takes less time to terminate.
3.	It takes more time for creation.	                            Thread takes less time for creation.
4.	It also takes more time for context switching.	              THread takes less time for context switching.
5.	Process is less efficient in term of communication.	          Thread is more efficient in term of communication.
6.	Process consume more resources.	                              Thread consume less resources.
7.	Process is isolated.	                                        Threads share memory.




################################################



### green threads  or greenlets


Greenlets are lightweight thread-like structures that are scheduled and managed inside the process. They are references to the part of the stack that is used by the thread.

In computer programming, green threads are threads that are scheduled by a runtime library or virtual machine (VM) instead of natively by the underlying operating system (OS). Green threads emulate multithreaded environments without relying on any native OS abilities, and they are managed in user space instead of kernel space, enabling them to work in environments that do not have native thread support


Compared to POSIX threads (pthreads), there is no stack allocated up front and there is only as much stack as is actually used by the greenlet

In python, we implement greenlets via the gevent package and we implement pthreads via python’s built-in threading module.

Both green threads (greenlets) and POSIX threads (pthreads) are mechanisms to support multithreaded execution of programs.

POSIX threads use the operating system’s native ability to manage multithreaded processes. When we run pthreads, the kernel schedules and manages the various threads that make up the process.

Green threads emulate multithreaded environments without relying on any native operating system capabilities. Green threads run code in user space that manages and schedules threads.

The key differences between greenlets and pthreads can be summarized as such:

pthreads	greenlets
pthreads can switch between threads pre-emptively, switching control from a running thread to a non-running thread at any time	greenlets only switch when control is explicitly given up by a thread - when using yield() or wait() - or when a thread performs a I/O blocking operation such as read or write
On multicore machines, pthreads can run more than one thread. However python’s Global Interpreter Lock (CPython Intepreter) prevents parallelism and concurrency is only effective for I/O-bound programs	greenlets can only run on one single CPU and is useful for I/O-bound programs
Race conditions can occur when implementing multi-threading code. Use locks to manage mutex to avoid race


####################################################

###### concurrancy vs parallelism

Concurrency means multiple tasks which start, run, and complete in overlapping time periods, in no specific order.

Parallelism is when multiple tasks OR several part of a unique task literally run at the same time, e.g. on a multi-core processor. Remember that Concurrency and parallelism are NOT the same thing.

Let’s understand more in detail that what I mean when I say Concurrency vs. Parallelism.

Concurrency
Concurrency is essentially applicable when we talk about minimum two tasks or more. When an application is capable of executing two tasks virtually at same time, we call it concurrent application. Though here tasks run looks like simultaneously, but essentially they MAY not. They take advantage of CPU time-slicing feature of operating system where each task run part of its task and then go to waiting state. When first task is in waiting state, CPU is assigned to second task to complete it’s part of task.

Operating system based on priority of tasks, thus, assigns CPU and other computing resources e.g. memory; turn by turn to all tasks and give them chance to complete. To end user, it seems that all tasks are running in parallel. This is called concurrency.

Parallelism
Parallelism does not require two tasks to exist. It literally physically run parts of tasks OR multiple tasks, at the same time using multi-core infrastructure of CPU, by assigning one core to each task or sub-task.

Parallelism requires hardware with multiple processing units, essentially. In single core CPU, you may get concurrency but NOT parallelism.

Differences between concurrency vs. parallelism
Now let’s list down remarkable differences between concurrency and parallelism.

Concurrency is when two tasks can start, run, and complete in overlapping time periods. Parallelism is when tasks literally run at the same time, eg. on a multi-core processor.

Concurrency is the composition of independently executing processes, while parallelism is the simultaneous execution of (possibly related) computations.

Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once.

An application can be concurrent – but not parallel, which means that it processes more than one task at the same time, but no two tasks are executing at same time instant.

An application can be parallel – but not concurrent, which means that it processes multiple sub-tasks of a task in multi-core CPU at same time.

An application can be neither parallel – nor concurrent, which means that it processes all tasks one at a time, sequentially.

An application can be both parallel – and concurrent, which means that it processes multiple tasks concurrently in multi-core CPU at same time .

That’s all about Concurrency vs. Parallelism, a very important concept in java multi-threading concepts.



###########################################

#### array
In computer science, an array data structure, or simply an array, is a data structure consisting of a collection of elements, each identified by at least one array index or key. An array is stored such that the position of each element can be computed from its index tuple by a mathematical formula.


### array Big O

What is an Array? 
An array is a collection of elements that are ideally of the same data type. When an array is created, the size of the array is specified at the time of declaration meaning it is a fixed size.
Arrays are also stored as one large contiguous block of memory starting at an index of zero.
This means that the elements get stored in consecutive slots of memory.

For example, when accessing an array at an index of 2, we are retrieving the third element.

Since the size of an array is specified at the time of declaration, part of the array contains the data, and the other portion of the array is empty so that it can store new elements if we wanted to add to it. If an array becomes too large, a new array must be created that copies over the original data and then doubles in size to create more empty space for future data to be stored. With an array, there is often memory allocated to the actual data stored and 
memory allocated to empty slots that may be filled in the future.

### big O to add/remove from array from first / last

For an array, accessing elements at a specified index has a constant time of Big O(1).
Inserting or removing from an array can come in three different forms: inserting/removing from the being, inserting/removing from the end, or inserting/removing from the middle. In order to add an element to the beginning of an array, we must shift every other element after it to a higher index. For example, If we wanted to add 2 to the beginning of the above so that it would now be at the zeroth index, 10 would now be at the first, 9 would be at the second and so on. Time taken will be proportional to the size of the list or Big O(n), n being the size of the list.

Adding to the end of the array is a lot simpler in terms of speed.
It involves adding the element to the next highest index of the array. This means that it is constant time and Big O(1) if the array is not already full. However, if the array is full it would involve having to create a new array and then copy the contents of the original into the new array which would be O(n).

The third case of insertion would be adding to a position between the beginning and end of the array which would be Big O(n). The same time complexity is also true for removing from an array.


Cost of accessing - O(1)

Insert/remove from beginnning - O(n)

Insert/Remove from end - O(1)

Insert/Remove from middle O(n)



##################################################


### linked list

Linked Lists
What is a linked list? 

A linked list consists of nodes where each node contains data and and a reference to the next node in the list.
Unlike an array, data is not stored in one contiguous block of memory and does not have a fixed size.
Instead, it consists of multiple blocks of memory at different addresses. 

This means that the size is variable because elements are allocated memory at runtime.

We can create and free nodes when we want or need without having to worry about memory. In order to access any node or element of the list, we need the address of the head node and need to then traverse the entire list in order to get to the desired element. Unlike an array, there is no reserved or unused memory. However, extra memory is used to store addresses for the next node. The last node’s address pointer will be undefined or 0 since it is the last node of the chain and will not have anything that comes after it.

Linked List Example

##### Big O for linked list :

When accessing elements of a linked list, speed is proportional to size of the list with Big O(n). Since we must traverse the entire list in order to get to the desired element, it is more costly compared to accessing elements of an array.


When inserting a node into the beginning of the list, it only involves creating a new node with an address that points to the old head. The time it takes to perform this is not dependent on the size of the list. This means that it will be constant time or a Big O(1). 


Inserting an element to the end of the list involves traversing the whole list and then creating a new node and adjusting the previous node’s address for the next node. Time taken will be proportional to the size of the list and Big O(n).


When we are inserting node into a position between the beginning and end of the linked list, we will have to traverse the list up until the specific point and then adjust the pointers with Big O(n). The same time complexity is also true for removing nodes from a linked list.

Cost of accessing - O(n)

Insert/remove from beginnning - O(1)

Insert/Remove from end - O(n)

Insert/Remove from middle O(n)


######################################################################
########## arraylist vs linked list

#### array list 

Java ArrayList class uses a dynamic array for storing the elements. It inherits AbstractList class and implements List interface.

The important points about Java ArrayList class are:

Java ArrayList class can contain duplicate elements.
Java ArrayList class maintains insertion order.
Java ArrayList class is non synchronized.
Java ArrayList allows random access because array works at the index basis.
In Java ArrayList class, manipulation is slow because a lot of shifting needs to occur if any element is removed from the array list.
Hierarchy of ArrayList class
As shown in the above diagram, Java ArrayList class extends AbstractList class which implements List interface. The List interface extends Collection and Iterable interfaces in hierarchical order.

ArrayList class declaration
Let's see the declaration for java.util.ArrayList class.

public class ArrayList<E> extends AbstractList<E> implements List<E>, RandomAccess, Cloneable, Serializable  


###linked list

Java LinkedList class uses a doubly linked list to store the elements. It provides a linked-list data structure. It inherits the AbstractList class and implements List and Deque interfaces.

The important points about Java LinkedList are:

Java LinkedList class can contain duplicate elements.
Java LinkedList class maintains insertion order.
Java LinkedList class is non synchronized.
In Java LinkedList class, manipulation is fast because no shifting needs to occur.
Java LinkedList class can be used as a list, stack or queue.
Hierarchy of LinkedList class
As shown in the above diagram, Java LinkedList class extends AbstractSequentialList class and implements List and Deque interfaces.

Doubly Linked List
In the case of a doubly linked list, we can add or remove elements from both sides.


## differences -
ArrayList and LinkedList, both implements java.util.List interface and provide capability to store and get objects as in ordered collections using simple API methods. Both are non synchronized classes. Still they are different in many aspects and we need to understand both classes in detail to make a wise decision when to use which class.

1. LinkedList vs ArrayList – Internal implementation
Both collections allow duplicate elements and maintain the insertion order of the elements.

LinkedList implements it with a doubly-linked list. ArrayList implements it with a dynamically resizing array. This will lead further differences in performance.

2. LinkedList vs ArrayList – Performance
2.1. Add operation
Adding element in ArrayList is O(1) operation if it doesn’t require resize of Array. If array is resized then it becomes O(log(n)).

Appending an element in LinkedList is O(1) operation, as it doesn’t require any navigation.

2.2. Remove operation
When we remove an element from ArrayList (in backing array), it moves all elements on right. It makes it close to O(n) in worst case (remove first element) and O(1) in best case (remove last element).

LinkedList remove operation gives O(1) performance because it just need to reset the pointers of previous and next nodes. No copy or movement is required.

2.3. Iteration
Iteration is the O(n) operation for both LinkedList and ArrayList where n is a number of an element.

2.4. Get operation
ArrayList provides get(int index) method which directly find the element at given index location. It is of order O(1).

LinkedList also provide get(int index) method BUT it first traverses all nodes to reach the correct node. It makes the performance variable. In best case it is O(1) and in worst case it is O(n).

3. LinkedList vs ArrayList – Conclusion
Until you are not dealing with very high volume of data, both the classes will give you same level of performance. Both provide ordered collection and both are non-synchronized as well.

LinkedList implements Deque interface as well, so it provides queue like FIFO functionality through methods such as peek() and poll().

As seen in performance comparison, ArrayList is better for storing and accessing data. LinkedList is better for manipulating data.

That’s all for arraylist vs linkedlist in java.

######################################################


#### garabage collection and generations

Java garbage collection is the process by which Java programs perform automatic memory management. Java programs compile to bytecode that can be run on a Java Virtual Machine, or JVM for short. When Java programs run on the JVM, objects are created on the heap, which is a portion of memory dedicated to the program. Eventually, some objects will no longer be needed. The garbage collector finds these unused objects and deletes them to free up memory.

How Java Garbage Collection Works
Java garbage collection is an automatic process. The programmer does not need to explicitly mark objects to be deleted. The garbage collection implementation lives in the JVM. Each JVM can implement garbage collection however it pleases; the only requirement is that it meets the JVM specification. Although there are many JVMs, Oracle’s HotSpot is by far the most common. It offers a robust and mature set of garbage collection options.

While HotSpot has multiple garbage collectors that are optimized for various use cases, all its garbage collectors follow the same basic process. In the first step, unreferenced objects are identified and marked as ready for garbage collection. In the second step, marked objects are deleted. Optionally, memory can be compacted after the garbage collector deletes objects, so remaining objects are in a contiguous block at the start of the heap. The compaction process makes it easier to allocate memory to new objects sequentially after the block of memory allocated to existing objects.

All of HotSpot’s garbage collectors implement a generational garbage collection strategy that categorizes objects by age. The rationale behind generational garbage collection is that most objects are short-lived and will be ready for garbage collection soon after creation.

Java Garbage Collection Heaps

Image via Wikipedia

##### The heap is divided into three sections:


Young Generation:

Newly created objects start in the Young Generation. The Young Generation is further subdivided into an Eden space, where all new objects start, and two Survivor spaces, where objects are moved from Eden after surviving one garbage collection cycle. When objects are garbage collected from the Young Generation, it is a minor garbage collection event.

Old Generation: 

Objects that are long-lived are eventually moved from the Young Generation to the Old Generation. When objects are garbage collected from the Old Generation, it is a major garbage collection event.

Permanent Generation: 

Metadata such as classes and methods are stored in the Permanent Generation. Classes that are no longer in use may be garbage collected from the Permanent Generation.
During a full garbage collection event, unused objects in all generations are garbage collected.

###Java Garbage Collection Best Practices
For many simple applications, Java garbage collection is not something that a programmer needs to consciously consider. However, for programmers who want to advance their Java skills, it is important to understand how Java garbage collection works and the ways in which it can be tuned.

Besides the basic mechanisms of garbage collection, one of the most important points to understand about garbage collection in Java is that it is non-deterministic, and there is no way to predict when garbage collection will occur at run time. It is possible to include a hint in the code to run the garbage collector with the System.gc() or Runtime.gc() methods, but they provide no guarantee that the garbage collector will actually run.

The best approach to tuning Java garbage collection is setting flags on the JVM. Flags can adjust the garbage collector to be used (e.g. Serial, G1, etc.), the initial and maximum size of the heap, the size of the heap sections (e.g. Young Generation, Old Generation), and more. The nature of the application being tuned is a good initial guide to settings. For example, the Parallel garbage collector is efficient but will frequently cause “stop the world” events, making it better suited for backend processing where long pauses for garbage collection are acceptable.

On the other hand, the CMS garbage collector is designed to minimize pauses, making it ideal for GUI applications where responsiveness is important. Additional fine-tuning can be accomplished by changing the size of the heap or its sections and measuring garbage collection efficiency using a tool like jstat.

#######################################################

##### CDC - change data capture

Change data capture CDC
In databases, change data capture (CDC) is a set of software design patterns used to determine (and track) 
the data that has changed so that action can be taken using the changed data.


 Change Data Capture (CDC) techniques are used to identify changes. CDC can be the basis to synchronize another system with the same incremental changes, or to store an audit trail of changes. The audit trail may subsequently be used for other uses e.g. to update a data warehouse or to run analyses across the changes e.g. to identify patterns of changes. In this blog post, I will describe the four common methods to perform CDC: Date_Modified, DIFF, Triggers, and Log-Based Change Data Capture. I will also share some of the challenges with each method.

Learn More About CDC
 
#### Four Methods of Change Data Capture

1. DATE_MODIFIED


Many transactional applications keep track of metadata in every row including who created and/or most-recently modified the row, as well as when the row was created and last modified. The approach to CDC in such an environment is to keep track of when changes are extracted, and in a subsequent run filter on the DATE_MODIFIED column to only retrieve rows that were modified since the most recent time data was extracted. This approach has a few challenges that may or may not be a concern, depending on the application:



Data deletes are a challenge because there is no DATE_MODIFIED for a deleted row (unless deletes are logical and update a flag in the row indicates the row was deleted). The extreme case of delete is truncate table which is uncommon in transactional applications but does occur sometimes.
DATE_MODIFIED must be available on all tables and must be reliably set. Database triggers may be a good way to set the values but these may introduce overhead on the transactional application.
Extracting the changes uses a lot of resources. Of course DATE_MODIFIED may be indexed to lower the impact of the select statement at the cost of storing (and continuously updating) the additional index.
Using DATE_MODIFIED for CDC works well for traditional data warehouse applications that are populated using Extract, Transform and Load (ETL) jobs, when the source tables don’t process deletes.

2. Diff

The diff method for change data capture compares the current state of the data with previous state of the data to identify what changed. Challenges with this approach include:

To perform the diff requires a lot of resources to compute the differences between the data, and resource consumption grows at least linearly with the growth in data volume.
CDC cannot be performed in real-time because the diff realistically takes too many resources to perform all the time.
Compared to the DATE_MODIFIED CDC method the diff method does not have the challenge with deleted rows. The diff method works well for low data volumes.

3. Triggers

Database triggers can be used to perform CDC in shadow tables. The shadow tables may store the entire row to keep track of every single column change, or only the primary key is stored as well as the operation type (insert, update or delete). The use of database triggers to perform CDC also has a few challenges:

Firing the trigger, and storing the row changes in a shadow table, introduces overhead. In an extreme case CDC may introduce 100% overhead on the transaction i.e. instead of .1 second it may take .2 seconds to complete a transaction.
The lower-overhead alternative to only store the primary key of the table requires a join back to the source table to retrieve the changes which (1) increases the load to retrieve the changes, and (2) loses intermediate changes if multiple changes took place on the same row.
Should the source application perform a truncate then chances are the trigger won’t fire and changes are not recorded. Also, if changes are made to tables then triggers and shadow tables may also have to be modified, recreated and/or recompiled which introduces extra overhead to manage and maintain the database.
CDC using database triggers lowers the overhead to extract the changes but increases the overhead to record the changes.

4. Log-Based Change Data Capture


Transactional databases store all changes in a transaction log in order to recover the committed state of the database should the database crash for whatever reason. Log-based CDC takes advantage of this aspect of the transactional database to read the changes from the log. The challenges with log-based CDC are:

Interpreting the changes in the transaction log is difficult because there are no documented standards on how the changes are stored (i.e. transaction logs from different database vendors are completely different), and there are many scenarios that must all be considered and tested (e.g. consider clustered databases, rollbacks and savepoints, many different ways to perform inserts, updates and deletes, etc.).
Database vendors may not provide an interface to the transaction logs – documented or not – and even if there is one it may be relatively slow and/or resource intensive.
Most databases have been optimized to only use internal identifiers to recover database row changes which is insufficient to perform CDC and record the changes on a different system. Supplemental logging of primary key columns is required to retrieve the context of the updates. The introduction of supplemental logging will increase the volume of data written to the transaction logs but generally only by a small percentage, and generally, there is very little if any measurable performance impact on the transactional application.
 

Learn More About How HVR Performs Log-Based Change Data Capture
 

Watch Video
 

### Benefits of Log-Based Change Data Capture
log based change data captureThe biggest benefit of log-based change data capture is the asynchronous nature of CDC: changes are captured independent of the source application performing the changes. Dedication and smart software engineers can take care of the biggest challenges. Log-based CDC is generally considered the superior approach to change data capture that can be applied to all possible scenarios including systems with extremely high transaction volumes.

HVR supports log-based CDC for all supported relational database sources. Trigger-based capture is still supported on most source databases for legacy reasons, or in scenarios when the source database does not provide the required functionality to perform log-based CDC (e.g. SQL Server Express Edition does not support supplemental logging of additional columns). Set-up of real-time data integration in HVR is simplified by a comprehensive GUI that takes care of all necessary steps to perform log-based CDC including the setup of supplemental logging as needed.

###############################################################




############################################################
