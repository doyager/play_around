process vs thread
parallelism vs concuranccy?

what are datastructures
What is big O notations?
what are arrays?
BIg O for add to start/end to array , remove from start/end from array , search an array 
array vs linkedlist
green threads
greenlets
garbage collection/
garbage collection generations


cache - for consistecy - write through and write back 
NOSQL

cdc - change data capture

how can you make a class immutable?
  Why Is the String Object Immutable in Java?
·         What Is the Difference Between Final, Finally, and Finalize?
·         What are the main 3 Object Oriented Programing (OOP) concepts?
·         What Is the Diamond Problem? (OOP question)
·         What Does Singleton Mean? (design pattern)
·         What is static keyword in java?
·         What is multithreading in java and how we can implement it ?
·         What are checked and unchecked exception in java?
·         What is Hash map and how it works (intermediate adv level)?

###################################################################################################################


##### CPU vs Memory 

RAM is used to save data. CPU time is used to process data.

There is no relationship between CPU and memory usage. A process can occupy all CPUs of a system but use only a minimal amount of memory. Also, a process can allocate all memory available on a system but only use minimal CPU time. So there is no relation between both.

Analogy:
It's the same relationship as your brain have with a book. The faster brain = the faster your read, the bigger the book = the more pages it can contain.

The CPU processes (performs instructions on things, such as adding) stuff in memory. RAM is just part of the memory 
pyramid (see below). So when you are processing lots of data, that data ( or maybe large portions of it) will likely get loaded into RAM so it is ready for the cpu, this is to speed things up because RAM is faster to access than storage devices. So CPU usage and RAM can often correlate, but don't have to.

A basic example might be an image editing program. I load up my 20MB jpeg, the program reads the entire image, and the OS keeps that in RAM for you (all working memory looks the same to the program, the OS decides if it goes to the page/swap file on disk or RAM). So the image is in RAM waiting to be processed, but I go for coffee before telling the program to apply some silly filter, so the CPU isn't doing anything: high RAM low CPU.

I come back, apply the filter to add some bubbles to the image, and the CPU goes to 100% and even more memory gets used because it keeps the preprocessed image in memory, so I can undo the change I just made. High RAM, high CPU.

When the program is done adding the bubbles, the CPU drops, but maybe not the memory.

Of course, it isn't quite this simple :-)




#### OOPs vs functional

Object-oriented programming used for performing few operations which are having common behavior and different variants. 
Functional programming is having a stateless programming model. 
Object-oriented programming is having a stateful programming model.

Functional programming is based on mathematical functions. Some of the popular functional programming languages 
include: Lisp, Python, Erlang, Haskell, Clojure, etc. 
Pure Functional Languages − These types of functional languages support only the functional paradigms.

In computer science, functional programming is a programming paradigm—a style of building the structure and elements of 
computer programs—that treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data


### OOPs

OOP “is a programming paradigm based on the concept of “objects”, which may contain data, in the form of fields, often known as attributes; and code, in the form of procedures, often known as methods. 

A feature of objects is that an object’s procedures can access and often modify the data fields of the object with which they are associated (objects have a notion of “this” or “self”)”, which essentially means, altering the ‘state’ of the object.
Furthermore, in most OOP languages, objects are instances of a class, and are seen as individual entities which interact with each other. These objects mimic the real world (to a certain degree).
Here’s an example in Ruby:
class Dog
  attr_accessor :name, :favorite_treat
  
  def initialize(name, favorite_treat)
    @name = name
    @favorite_treat = favorite_treat
  end

  def change_favorite_treat(treat)
    @favorite_treat = treat
  end
end
charlie = Dog.new("Charlie", "bacon")
We are creating a class (almost like a template, if you will) called Dog. We can assume all dogs have a name and a favorite treat, so we ‘initialize’ with a name and favorite treat parameter. We now make a new instance of the dog class, named charlie. Let’s say Charlie is a fickle dog, and his favorite treat has changed from bacon to t-bones.
charlie.change_favorite_treat('t-bone')
charlie.favorite_treat >> 't-bone'
By using the change_favorite_treat method, we have successfully changed the “state” of Charlie, and now when we access his ‘favorite_treat’ attribute, we get ‘t-bone’.



#### FP - FunctionalProgramming 

Functional programming
Put very simply, functional programming is a language that focuses on the computation of pure functions. The keyword there is ‘pure’ — everything revolves around keeping everything ‘pure’. What exactly do we mean by pure?
There is a complete separation between the data of a program, and the behaviors of a program
All objects created in functional programming are immutable (once something is created, it can’t be changed)
Shared state is avoided (objects do not share scope with other objects)
Adherence to pure functions (explained below)
Pure functions
A pure function is a function where:
The return value only depends on the input (if you input the same value, you will always return the same value)
There are no side effects (for example: no network or database calls which could affect the return value)
They do not alter the data that was passed into them. We only want to describe how the input will be changed (think destructive vs non-destructive)
Here are some examples of an impure function:
function number(num){
  num * Math.random()
}
function hello(greeting){
  console.log(greeting)
}
var totalPeople = 10
function totalVotes(votes){
 return votes * totalPeople
}
The outcome of number has nothing to do with what we input into it with num, as it is multiplying the input with a random number. Not pure! With pure functions, we ONLY care about return values. So, the function hello isn’t pure in the fact that it is creating a ‘side-effect’, which is the console logging. The function totalVotes depends on a variable outside of its scope (shared state!), which is a no no!
Here’s an example of a pure function:
function plusTwo(num){
  return num + 2
}
The outcome of plusTwo depends only on the input, num.
OOP vs FP
To highlight how different the approaches are in OOP and FP, I’ve borrowed this example below:
You run a company and you just decided to give all your employees a $10,000.00 raise. How would you tackle this situation programatically?
In OOP:
Create Employee class which initializes with name and salary, has a change salary instance method
Create instances of employees
Use the each method to change salary attribute of employees by +10,000
In FP:
Create employees array, which is an array of arrays with name and corresponding salary
Create a change_salary function which returns a copy of a single employee with the salary field updated
Create a change_salaries function which maps through the employee array and delegates the calculation of the new salary to change_salary
Use both methods to create a new dataset, named ‘happier employees’

OOPs vs FP :

We can see that the FP approach uses pure functions and adheres to immutability (note the use of map instead of each, where map returns a new altered dataset while each alters the attributes/state of the objects). 

With OOP, we cannot easily identify if the object has had the function called on it unless we start from the beginning and track if this has happened, whereas in FP, the object itself is now a new object with a different name, which makes it considerably easier to know what changes have been made.
(Example and explanation taken from: https://www.codenewbie.org/blogs/object-oriented-programming-vs-functional-programming)
So, what’s the debate about?


Quite obviously, those on team OOP argue that OOP is a better approach to creating programs, while those on team FP argue that FP is better. How so?Team OOP argues that the concept of inheritance (new objects taking on the attributes/methods of existing objects letting us reuse more code) and encapsulation (the data and methods related to a certain object being bound together, creating independent, protected entities) makes it easier to manage and manipulate data. Team FP argues that the separation of data and methods, as well as the high level of abstraction leave less room for errors.
It seems the general consensus is that OOP and FP are better depending on the situation, so we won’t be hearing about the end of this debate anytime soon.





#########################################


#####class vs object


In object-oriented terminology, 

a class is a template for defining objects. 
It specifies the names and types of variables that can exist in an object, as well as "methods"--procedures for operating on those variables. A class can be thought of as a "type", with the objects being a "variable" of that type. Multiple objects, or instances of a class can be created in a single HLU program, just as you declare multiple variables of the same type in any program.
For example, the TextItem class is a template for creating an object that contains a text string. This object will have a particular set of text attributes such as font, size, and color. If we set the values of the object variables--resources--in a certain way, we can create the TextItem object "Hello World". Resources that are available for objects of the TextItem class include the text string ("Hello World" in this case), the type of font, the color of the characters, the size of the characters, the line width of the characters, etc. A TextItem object is thus an instance of the TextItem class with a set of values assigned to the associated resources. We can create a second TextItem object if we want to with a new set of resource values such as: "THIS IS ALSO A TEXTITEM OBJECT."

Class versus object
Many people get confused by the difference between class and object. The difference is simple and conceptual. 

Class:
A class is a template for objects. A class defines object properties including a valid range of values, and a default value. A class also describes object behavior. 

Object:
An object is a member or an "instance" of a class. An object has a state in which all of its properties have values that you either explicitly define or that are defined by default settings.
This subtle conceptual difference between classes and objects shows why there is a tendency to want to use them interchangeably.


######################################

### data structures:

In computer science, a data structure is a data organization, management, and storage format that enables efficient access and modification. More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data

 anything that can store data can be called as a data structure, 
 
 hence Integer, Float, Boolean, Char etc, all are data structures. They are known as Primitive Data Structures.
 
 Some example of Abstract Data Structure are :
Linked List.
Tree.
Graph.
Stack, Queue etc.

Data type: a set of values together with operations (specified as input-output behavior)
Data structure: a physical implementation of a data type

 
############################

Big O notation:

Big O Notation
What is the Big O Notation? Big O is the way we describe the performance efficiency or complexity of algorithms.
we can use Big O to analyse time and space
we can analyse 
-worst case
- best case
- average case
We typically look at worst case 

we must first understand Big O and some of the different time complexity possibilities. Below are three different possibilities for the speed of an algorithm.
O(1): Executes in the same time regardless of the size of the input
O(n): Executes linearly and proportionally to the size of the input
O(n²): Performance is directly proportional to the square of the size of the input (ex: nested iterations, loops)


Rules to form B O calculation 
- Different steps gets added
- Drop constants , O(2N) is wrong we just need to say O(N) 
- 
- Drop non dominate terms[ Eg : O(n-sq) < O(n + n-sq) < O (n-sq+n-sq , => O(n-sq)]

###############################################################


##### data profiling

Data profiling is the process of examining the data available from an existing information source (e.g. a database or a file) and collecting statistics or informative summaries about that data. The purpose of these statistics may be to: Find out whether existing data can be easily used for other purposes

######################

#### process vs thread  

Process:
Process means any program is in execution. Process control block controls the operation of any process. Process control block contains the information about processes for example: Process priority, process id, process state, CPU, register etc. A process can creates other processes which are known as Child Processes. Process takes more time to terminate and it is isolated means it does not share memory with any other process.

Thread:
A thread is a basic unit of CPU utilization

Thread is the segment of a process means a process can have multiple threads and these multiple threads are contained within a process. A thread have 3 states: running, ready, and blocked.

Thread takes less time to terminate as compared to process and like process threads do not isolate.

A thread is a basic unit of CPU utilization. It is also referred to as a “lightweight process”.

A thread is a sequence of instructions within a process and it behaves like “a process within a process”. It differs from a process because it does not have its own Process Control Block (collection of information about the processes). Usually, multiple threads are created within a process. Threads execute within a process and processes execute within the operating system kernel.

A thread comprises:

thread ID
program counter
register set
stack
A thread shares resources with its peer threads (all other threads in a particular task), such as:

code section
data section
any operating resources which are available to the task



Difference between Process and Thread:

S.NO	PROCESS	THREAD
1.	Process means any program is in execution.                  	Thread means segment of a process.
2.	Process takes more time to terminate.	                        Thread takes less time to terminate.
3.	It takes more time for creation.	                            Thread takes less time for creation.
4.	It also takes more time for context switching.	              THread takes less time for context switching.
5.	Process is less efficient in term of communication.	          Thread is more efficient in term of communication.
6.	Process consume more resources.	                              Thread consume less resources.
7.	Process is isolated.	                                        Threads share memory.




################################################



### green threads  or greenlets


Greenlets are lightweight thread-like structures that are scheduled and managed inside the process. They are references to the part of the stack that is used by the thread.

In computer programming, green threads are threads that are scheduled by a runtime library or virtual machine (VM) instead of natively by the underlying operating system (OS). Green threads emulate multithreaded environments without relying on any native OS abilities, and they are managed in user space instead of kernel space, enabling them to work in environments that do not have native thread support


Compared to POSIX threads (pthreads), there is no stack allocated up front and there is only as much stack as is actually used by the greenlet

In python, we implement greenlets via the gevent package and we implement pthreads via python’s built-in threading module.

Both green threads (greenlets) and POSIX threads (pthreads) are mechanisms to support multithreaded execution of programs.

POSIX threads use the operating system’s native ability to manage multithreaded processes. When we run pthreads, the kernel schedules and manages the various threads that make up the process.

Green threads emulate multithreaded environments without relying on any native operating system capabilities. Green threads run code in user space that manages and schedules threads.

The key differences between greenlets and pthreads can be summarized as such:

pthreads	greenlets
pthreads can switch between threads pre-emptively, switching control from a running thread to a non-running thread at any time	greenlets only switch when control is explicitly given up by a thread - when using yield() or wait() - or when a thread performs a I/O blocking operation such as read or write
On multicore machines, pthreads can run more than one thread. However python’s Global Interpreter Lock (CPython Intepreter) prevents parallelism and concurrency is only effective for I/O-bound programs	greenlets can only run on one single CPU and is useful for I/O-bound programs
Race conditions can occur when implementing multi-threading code. Use locks to manage mutex to avoid race


####################################################

###### concurrancy vs parallelism

Concurrency means multiple tasks which start, run, and complete in overlapping time periods, in no specific order.

Parallelism is when multiple tasks OR several part of a unique task literally run at the same time, e.g. on a multi-core processor. Remember that Concurrency and parallelism are NOT the same thing.

Let’s understand more in detail that what I mean when I say Concurrency vs. Parallelism.

Concurrency
Concurrency is essentially applicable when we talk about minimum two tasks or more. When an application is capable of executing two tasks virtually at same time, we call it concurrent application. Though here tasks run looks like simultaneously, but essentially they MAY not. They take advantage of CPU time-slicing feature of operating system where each task run part of its task and then go to waiting state. When first task is in waiting state, CPU is assigned to second task to complete it’s part of task.

Operating system based on priority of tasks, thus, assigns CPU and other computing resources e.g. memory; turn by turn to all tasks and give them chance to complete. To end user, it seems that all tasks are running in parallel. This is called concurrency.

Parallelism
Parallelism does not require two tasks to exist. It literally physically run parts of tasks OR multiple tasks, at the same time using multi-core infrastructure of CPU, by assigning one core to each task or sub-task.

Parallelism requires hardware with multiple processing units, essentially. In single core CPU, you may get concurrency but NOT parallelism.

Differences between concurrency vs. parallelism
Now let’s list down remarkable differences between concurrency and parallelism.

Concurrency is when two tasks can start, run, and complete in overlapping time periods. Parallelism is when tasks literally run at the same time, eg. on a multi-core processor.

Concurrency is the composition of independently executing processes, while parallelism is the simultaneous execution of (possibly related) computations.

Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once.

An application can be concurrent – but not parallel, which means that it processes more than one task at the same time, but no two tasks are executing at same time instant.

An application can be parallel – but not concurrent, which means that it processes multiple sub-tasks of a task in multi-core CPU at same time.

An application can be neither parallel – nor concurrent, which means that it processes all tasks one at a time, sequentially.

An application can be both parallel – and concurrent, which means that it processes multiple tasks concurrently in multi-core CPU at same time .

That’s all about Concurrency vs. Parallelism, a very important concept in java multi-threading concepts.



###########################################

#### array
In computer science, an array data structure, or simply an array, is a data structure consisting of a collection of elements, each identified by at least one array index or key. An array is stored such that the position of each element can be computed from its index tuple by a mathematical formula.


### array Big O

What is an Array? 
An array is a collection of elements that are ideally of the same data type. When an array is created, the size of the array is specified at the time of declaration meaning it is a fixed size.
Arrays are also stored as one large contiguous block of memory starting at an index of zero.
This means that the elements get stored in consecutive slots of memory.

For example, when accessing an array at an index of 2, we are retrieving the third element.

Since the size of an array is specified at the time of declaration, part of the array contains the data, and the other portion of the array is empty so that it can store new elements if we wanted to add to it. If an array becomes too large, a new array must be created that copies over the original data and then doubles in size to create more empty space for future data to be stored. With an array, there is often memory allocated to the actual data stored and 
memory allocated to empty slots that may be filled in the future.

### big O to add/remove from array from first / last

For an array, accessing elements at a specified index has a constant time of Big O(1).
Inserting or removing from an array can come in three different forms: inserting/removing from the being, inserting/removing from the end, or inserting/removing from the middle. In order to add an element to the beginning of an array, we must shift every other element after it to a higher index. For example, If we wanted to add 2 to the beginning of the above so that it would now be at the zeroth index, 10 would now be at the first, 9 would be at the second and so on. Time taken will be proportional to the size of the list or Big O(n), n being the size of the list.

Adding to the end of the array is a lot simpler in terms of speed.
It involves adding the element to the next highest index of the array. This means that it is constant time and Big O(1) if the array is not already full. However, if the array is full it would involve having to create a new array and then copy the contents of the original into the new array which would be O(n).

The third case of insertion would be adding to a position between the beginning and end of the array which would be Big O(n). The same time complexity is also true for removing from an array.


Cost of accessing - O(1)

Insert/remove from beginnning - O(n)

Insert/Remove from end - O(1)

Insert/Remove from middle O(n)



##################################################


### linked list

Linked Lists
What is a linked list? 

A linked list consists of nodes where each node contains data and and a reference to the next node in the list.
Unlike an array, data is not stored in one contiguous block of memory and does not have a fixed size.
Instead, it consists of multiple blocks of memory at different addresses. 

This means that the size is variable because elements are allocated memory at runtime.

We can create and free nodes when we want or need without having to worry about memory. In order to access any node or element of the list, we need the address of the head node and need to then traverse the entire list in order to get to the desired element. Unlike an array, there is no reserved or unused memory. However, extra memory is used to store addresses for the next node. The last node’s address pointer will be undefined or 0 since it is the last node of the chain and will not have anything that comes after it.

Linked List Example

##### Big O for linked list :

When accessing elements of a linked list, speed is proportional to size of the list with Big O(n). Since we must traverse the entire list in order to get to the desired element, it is more costly compared to accessing elements of an array.


When inserting a node into the beginning of the list, it only involves creating a new node with an address that points to the old head. The time it takes to perform this is not dependent on the size of the list. This means that it will be constant time or a Big O(1). 


Inserting an element to the end of the list involves traversing the whole list and then creating a new node and adjusting the previous node’s address for the next node. Time taken will be proportional to the size of the list and Big O(n).


When we are inserting node into a position between the beginning and end of the linked list, we will have to traverse the list up until the specific point and then adjust the pointers with Big O(n). The same time complexity is also true for removing nodes from a linked list.

Cost of accessing - O(n)

Insert/remove from beginnning - O(1)

Insert/Remove from end - O(n)

Insert/Remove from middle O(n)


######################################################################
########## arraylist vs linked list

#### array list 

Java ArrayList class uses a dynamic array for storing the elements. It inherits AbstractList class and implements List interface.

The important points about Java ArrayList class are:

Java ArrayList class can contain duplicate elements.
Java ArrayList class maintains insertion order.
Java ArrayList class is non synchronized.
Java ArrayList allows random access because array works at the index basis.
In Java ArrayList class, manipulation is slow because a lot of shifting needs to occur if any element is removed from the array list.
Hierarchy of ArrayList class
As shown in the above diagram, Java ArrayList class extends AbstractList class which implements List interface. The List interface extends Collection and Iterable interfaces in hierarchical order.

ArrayList class declaration
Let's see the declaration for java.util.ArrayList class.

public class ArrayList<E> extends AbstractList<E> implements List<E>, RandomAccess, Cloneable, Serializable  


###linked list

Java LinkedList class uses a doubly linked list to store the elements. It provides a linked-list data structure. It inherits the AbstractList class and implements List and Deque interfaces.

The important points about Java LinkedList are:

Java LinkedList class can contain duplicate elements.
Java LinkedList class maintains insertion order.
Java LinkedList class is non synchronized.
In Java LinkedList class, manipulation is fast because no shifting needs to occur.
Java LinkedList class can be used as a list, stack or queue.
Hierarchy of LinkedList class
As shown in the above diagram, Java LinkedList class extends AbstractSequentialList class and implements List and Deque interfaces.

Doubly Linked List
In the case of a doubly linked list, we can add or remove elements from both sides.


## differences -
ArrayList and LinkedList, both implements java.util.List interface and provide capability to store and get objects as in ordered collections using simple API methods. Both are non synchronized classes. Still they are different in many aspects and we need to understand both classes in detail to make a wise decision when to use which class.

1. LinkedList vs ArrayList – Internal implementation
Both collections allow duplicate elements and maintain the insertion order of the elements.

LinkedList implements it with a doubly-linked list. ArrayList implements it with a dynamically resizing array. This will lead further differences in performance.

2. LinkedList vs ArrayList – Performance
2.1. Add operation
Adding element in ArrayList is O(1) operation if it doesn’t require resize of Array. If array is resized then it becomes O(log(n)).

Appending an element in LinkedList is O(1) operation, as it doesn’t require any navigation.

2.2. Remove operation
When we remove an element from ArrayList (in backing array), it moves all elements on right. It makes it close to O(n) in worst case (remove first element) and O(1) in best case (remove last element).

LinkedList remove operation gives O(1) performance because it just need to reset the pointers of previous and next nodes. No copy or movement is required.

2.3. Iteration
Iteration is the O(n) operation for both LinkedList and ArrayList where n is a number of an element.

2.4. Get operation
ArrayList provides get(int index) method which directly find the element at given index location. It is of order O(1).

LinkedList also provide get(int index) method BUT it first traverses all nodes to reach the correct node. It makes the performance variable. In best case it is O(1) and in worst case it is O(n).

3. LinkedList vs ArrayList – Conclusion
Until you are not dealing with very high volume of data, both the classes will give you same level of performance. Both provide ordered collection and both are non-synchronized as well.

LinkedList implements Deque interface as well, so it provides queue like FIFO functionality through methods such as peek() and poll().

As seen in performance comparison, ArrayList is better for storing and accessing data. LinkedList is better for manipulating data.

That’s all for arraylist vs linkedlist in java.

######################################################


#### garabage collection and generations

Java garbage collection is the process by which Java programs perform automatic memory management. Java programs compile to bytecode that can be run on a Java Virtual Machine, or JVM for short. When Java programs run on the JVM, objects are created on the heap, which is a portion of memory dedicated to the program. Eventually, some objects will no longer be needed. The garbage collector finds these unused objects and deletes them to free up memory.

How Java Garbage Collection Works
Java garbage collection is an automatic process. The programmer does not need to explicitly mark objects to be deleted. The garbage collection implementation lives in the JVM. Each JVM can implement garbage collection however it pleases; the only requirement is that it meets the JVM specification. Although there are many JVMs, Oracle’s HotSpot is by far the most common. It offers a robust and mature set of garbage collection options.

While HotSpot has multiple garbage collectors that are optimized for various use cases, all its garbage collectors follow the same basic process. In the first step, unreferenced objects are identified and marked as ready for garbage collection. In the second step, marked objects are deleted. Optionally, memory can be compacted after the garbage collector deletes objects, so remaining objects are in a contiguous block at the start of the heap. The compaction process makes it easier to allocate memory to new objects sequentially after the block of memory allocated to existing objects.

All of HotSpot’s garbage collectors implement a generational garbage collection strategy that categorizes objects by age. The rationale behind generational garbage collection is that most objects are short-lived and will be ready for garbage collection soon after creation.

Java Garbage Collection Heaps

Image via Wikipedia

##### The heap is divided into three sections:


Young Generation:

Newly created objects start in the Young Generation. The Young Generation is further subdivided into an Eden space, where all new objects start, and two Survivor spaces, where objects are moved from Eden after surviving one garbage collection cycle. When objects are garbage collected from the Young Generation, it is a minor garbage collection event.

Old Generation: 

Objects that are long-lived are eventually moved from the Young Generation to the Old Generation. When objects are garbage collected from the Old Generation, it is a major garbage collection event.

Permanent Generation: 

Metadata such as classes and methods are stored in the Permanent Generation. Classes that are no longer in use may be garbage collected from the Permanent Generation.
During a full garbage collection event, unused objects in all generations are garbage collected.

###Java Garbage Collection Best Practices
For many simple applications, Java garbage collection is not something that a programmer needs to consciously consider. However, for programmers who want to advance their Java skills, it is important to understand how Java garbage collection works and the ways in which it can be tuned.

Besides the basic mechanisms of garbage collection, one of the most important points to understand about garbage collection in Java is that it is non-deterministic, and there is no way to predict when garbage collection will occur at run time. It is possible to include a hint in the code to run the garbage collector with the System.gc() or Runtime.gc() methods, but they provide no guarantee that the garbage collector will actually run.

The best approach to tuning Java garbage collection is setting flags on the JVM. Flags can adjust the garbage collector to be used (e.g. Serial, G1, etc.), the initial and maximum size of the heap, the size of the heap sections (e.g. Young Generation, Old Generation), and more. The nature of the application being tuned is a good initial guide to settings. For example, the Parallel garbage collector is efficient but will frequently cause “stop the world” events, making it better suited for backend processing where long pauses for garbage collection are acceptable.

On the other hand, the CMS garbage collector is designed to minimize pauses, making it ideal for GUI applications where responsiveness is important. Additional fine-tuning can be accomplished by changing the size of the heap or its sections and measuring garbage collection efficiency using a tool like jstat.

#######################################################

##### CDC - change data capture

Change data capture CDC
In databases, change data capture (CDC) is a set of software design patterns used to determine (and track) 
the data that has changed so that action can be taken using the changed data.


 Change Data Capture (CDC) techniques are used to identify changes. CDC can be the basis to synchronize another system with the same incremental changes, or to store an audit trail of changes. The audit trail may subsequently be used for other uses e.g. to update a data warehouse or to run analyses across the changes e.g. to identify patterns of changes. In this blog post, I will describe the four common methods to perform CDC: Date_Modified, DIFF, Triggers, and Log-Based Change Data Capture. I will also share some of the challenges with each method.

Learn More About CDC
 
#### Four Methods of Change Data Capture

1. DATE_MODIFIED


Many transactional applications keep track of metadata in every row including who created and/or most-recently modified the row, as well as when the row was created and last modified. The approach to CDC in such an environment is to keep track of when changes are extracted, and in a subsequent run filter on the DATE_MODIFIED column to only retrieve rows that were modified since the most recent time data was extracted. This approach has a few challenges that may or may not be a concern, depending on the application:



Data deletes are a challenge because there is no DATE_MODIFIED for a deleted row (unless deletes are logical and update a flag in the row indicates the row was deleted). The extreme case of delete is truncate table which is uncommon in transactional applications but does occur sometimes.
DATE_MODIFIED must be available on all tables and must be reliably set. Database triggers may be a good way to set the values but these may introduce overhead on the transactional application.
Extracting the changes uses a lot of resources. Of course DATE_MODIFIED may be indexed to lower the impact of the select statement at the cost of storing (and continuously updating) the additional index.
Using DATE_MODIFIED for CDC works well for traditional data warehouse applications that are populated using Extract, Transform and Load (ETL) jobs, when the source tables don’t process deletes.

2. Diff

The diff method for change data capture compares the current state of the data with previous state of the data to identify what changed. Challenges with this approach include:

To perform the diff requires a lot of resources to compute the differences between the data, and resource consumption grows at least linearly with the growth in data volume.
CDC cannot be performed in real-time because the diff realistically takes too many resources to perform all the time.
Compared to the DATE_MODIFIED CDC method the diff method does not have the challenge with deleted rows. The diff method works well for low data volumes.

3. Triggers

Database triggers can be used to perform CDC in shadow tables. The shadow tables may store the entire row to keep track of every single column change, or only the primary key is stored as well as the operation type (insert, update or delete). The use of database triggers to perform CDC also has a few challenges:

Firing the trigger, and storing the row changes in a shadow table, introduces overhead. In an extreme case CDC may introduce 100% overhead on the transaction i.e. instead of .1 second it may take .2 seconds to complete a transaction.
The lower-overhead alternative to only store the primary key of the table requires a join back to the source table to retrieve the changes which (1) increases the load to retrieve the changes, and (2) loses intermediate changes if multiple changes took place on the same row.
Should the source application perform a truncate then chances are the trigger won’t fire and changes are not recorded. Also, if changes are made to tables then triggers and shadow tables may also have to be modified, recreated and/or recompiled which introduces extra overhead to manage and maintain the database.
CDC using database triggers lowers the overhead to extract the changes but increases the overhead to record the changes.

4. Log-Based Change Data Capture


Transactional databases store all changes in a transaction log in order to recover the committed state of the database should the database crash for whatever reason. Log-based CDC takes advantage of this aspect of the transactional database to read the changes from the log. The challenges with log-based CDC are:

Interpreting the changes in the transaction log is difficult because there are no documented standards on how the changes are stored (i.e. transaction logs from different database vendors are completely different), and there are many scenarios that must all be considered and tested (e.g. consider clustered databases, rollbacks and savepoints, many different ways to perform inserts, updates and deletes, etc.).
Database vendors may not provide an interface to the transaction logs – documented or not – and even if there is one it may be relatively slow and/or resource intensive.
Most databases have been optimized to only use internal identifiers to recover database row changes which is insufficient to perform CDC and record the changes on a different system. Supplemental logging of primary key columns is required to retrieve the context of the updates. The introduction of supplemental logging will increase the volume of data written to the transaction logs but generally only by a small percentage, and generally, there is very little if any measurable performance impact on the transactional application.
 

Learn More About How HVR Performs Log-Based Change Data Capture
 

Watch Video
 

### Benefits of Log-Based Change Data Capture
log based change data captureThe biggest benefit of log-based change data capture is the asynchronous nature of CDC: changes are captured independent of the source application performing the changes. Dedication and smart software engineers can take care of the biggest challenges. Log-based CDC is generally considered the superior approach to change data capture that can be applied to all possible scenarios including systems with extremely high transaction volumes.

HVR supports log-based CDC for all supported relational database sources. Trigger-based capture is still supported on most source databases for legacy reasons, or in scenarios when the source database does not provide the required functionality to perform log-based CDC (e.g. SQL Server Express Edition does not support supplemental logging of additional columns). Set-up of real-time data integration in HVR is simplified by a comprehensive GUI that takes care of all necessary steps to perform log-based CDC including the setup of supplemental logging as needed.

###############################################################


####### . how can you make a class immutable?


### reason for  immutable class  - thread safe , caching purpose so that values dont change

An immutable class is good for caching purpose because you don’t need to worry about the value changes. Other benefit of immutable class is that it is inherently thread-safe, so you don’t need to worry about thread safety in case of multi-threaded environment.


### To create an immutable class in java, you have to do following steps.

Declare the class as final so it can’t be extended.
Make all fields private so that direct access is not allowed.
Don’t provide setter methods for variables
Make all mutable fields final so that it’s value can be assigned only once.
Initialize all the fields via a constructor performing deep copy.
Perform cloning of objects in the getter methods to return a copy rather than returning the actual object reference.


ackage com.journaldev.java;

import java.util.HashMap;
import java.util.Iterator;

public final class FinalClassExample {

	private final int id;
	
	private final String name;
	
	private final HashMap<String,String> testMap;
	
	public int getId() {
		return id;
	}


	public String getName() {
		return name;
	}

	/**
	 * Accessor function for mutable objects
	 */
	public HashMap<String, String> getTestMap() {
		//return testMap;
		return (HashMap<String, String>) testMap.clone();
	}

	/**
	 * Constructor performing Deep Copy
	 * @param i
	 * @param n
	 * @param hm
	 */
	
	public FinalClassExample(int i, String n, HashMap<String,String> hm){
		System.out.println("Performing Deep Copy for Object initialization");
		this.id=i;
		this.name=n;
		HashMap<String,String> tempMap=new HashMap<String,String>();
		String key;
		Iterator<String> it = hm.keySet().iterator();
		while(it.hasNext()){
			key=it.next();
			tempMap.put(key, hm.get(key));
		}
		this.testMap=tempMap;
	}
	
	
	/**
	 * Constructor performing Shallow Copy
	 * @param i
	 * @param n
	 * @param hm
	 */
	/**
	public FinalClassExample(int i, String n, HashMap<String,String> hm){
		System.out.println("Performing Shallow Copy for Object initialization");
		this.id=i;
		this.name=n;
		this.testMap=hm;
	}
	*/
	
	/**
	 * To test the consequences of Shallow Copy and how to avoid it with Deep Copy for creating immutable classes
	 * @param args
	 */
	public static void main(String[] args) {
		HashMap<String, String> h1 = new HashMap<String,String>();
		h1.put("1", "first");
		h1.put("2", "second");
		
		String s = "original";
		
		int i=10;
		
		FinalClassExample ce = new FinalClassExample(i,s,h1);
		
		//Lets see whether its copy by field or reference
		System.out.println(s==ce.getName());
		System.out.println(h1 == ce.getTestMap());
		//print the ce values
		System.out.println("ce id:"+ce.getId());
		System.out.println("ce name:"+ce.getName());
		System.out.println("ce testMap:"+ce.getTestMap());
		//change the local variable values
		i=20;
		s="modified";
		h1.put("3", "third");
		//print the values again
		System.out.println("ce id after local variable change:"+ce.getId());
		System.out.println("ce name after local variable change:"+ce.getName());
		System.out.println("ce testMap after local variable change:"+ce.getTestMap());
		
		HashMap<String, String> hmTest = ce.getTestMap();
		hmTest.put("4", "new");
		
		System.out.println("ce testMap after changing variable from accessor methods:"+ce.getTestMap());

	}

}

############################################################


#### . Why Is the String Object Immutable in Java?

he string is Immutable in Java because String objects are cached in String pool. Since cached String literals are shared between multiple clients there is always a risk, where one client's action would affect all another client. For example, if one client changes the value of String "Test" to "TEST", all other clients will also see that value as explained in the first example. Since caching of String objects was important from performance reason this risk was avoided by making String class Immutable. At the same time, String was made final so that no one can compromise invariant of String class e.g. Immutability, Caching, hashcode calculation etc by extending and overriding behaviors. Another reason of why String class is immutable could die due to HashMap.

Since Strings are very popular as HashMap key, it's important for them to be immutable so that they can retrieve the value object which was stored in HashMap. Since HashMap works in the principle of hashing, which requires same has value to function properly. Mutable String would produce two different hashcodes at the time of insertion and retrieval if contents of String was modified after insertion, potentially losing the value object in the map.


Read more: https://javarevisited.blogspot.com/2010/10/why-string-is-immutable-or-final-in-java.html#ixzz6BE1wzRwP


############################################################

##### What Is the Difference Between Final, Finally, and Finalize?


Final is a keyword. Final is used to apply restrictions on class, method and variable. Final class can't be inherited, final method can't be overridden and final variable value can't be changed.	

Finally is a block. Finally is used to place important code, it will be executed whether exception is handled or not.	


Finalize is a method. Finalize is used to perform clean up processing just before object is garbage collected.
			

############################################################

######## OOPS and What are the main 3 Object Oriented Programing (OOP) concepts

A programming language structure wherein the data and their associated processing ("methods") are defined as self-contained entities called "objects." The norm today, object-oriented programming (OOP) languages, such as C++ and Java, provide a formal set of rules for creating and managing objects. The data are stored in a traditional relational database or in an object database if the data have a complex structure. See O-R mapping and object database.

There are three major features in object-oriented programming that makes them different than non-OOP languages: encapsulation, inheritance and polymorphism.

### Encapsulation Enforces Modularity
Encapsulation refers to the creation of self-contained modules that bind processing functions to the data. These user-defined data types are called "classes," and one instance of a class is an "object." For example, in a payroll system, a class could be Manager, and Pat and Jan could be two instances (two objects) of the Manager class. Encapsulation ensures good code modularity, which keeps routines separate and less prone to conflict with each other.

### Inheritance Passes "Knowledge" Down
Classes are created in hierarchies, and inheritance allows the structure and methods in one class to be passed down the hierarchy. That means less programming is required when adding functions to complex systems. If a step is added at the bottom of a hierarchy, only the processing and data associated with that unique step needs to be added. Everything else is inherited. The ability to reuse existing objects is considered a major advantage of object technology.

### Polymorphism Takes any Shape
Object-oriented programming allows procedures about objects to be created whose exact type is not known until runtime. For example, a screen cursor may change its shape from an arrow to a line depending on the program mode. The routine to move the cursor on screen in response to mouse movement would be written for "cursor," and polymorphism allows that cursor to take on whatever shape is required at runtime. It also allows new shapes to be easily integrated.



############################################################


########### Diamond problem in java 
##### . What Is the Diamond Problem? (OOP question)

The “diamond problem” is an ambiguity that can arise as a consequence of allowing multiple inheritance. It is a serious problem for languages (like C++) that allow for multiple inheritance of state. In Java, however, multiple inheritance is not allowed for classes, only for interfaces, and these do not contain state.

Consider the following situation:

    interface A {
        default void m() { ... }        
    }
    interface B extends A {}
    interface C extends A {}
    class D implements B, C {}

The rules for default method selection given on the previous page provide a straightforward interpretation of this scenario and its variants.

In the initial case (the code above), the implementation of m inherited by D is unambiguously that defined by A—there is no other possibility. If the situation is changed so that B now also declares a default implementation of m, that becomes the implementation that D inherits by the “most specific implementation” rule. But if both B and C provide default implementations, then they conflict, and D must provide an overriding declaration, possibly using the syntax X.super.m(...) in the body of m to explicitly choose one of the inherited methods. All three cases are clearly covered by the rules for method resolution explained in the previous answer.

Default methods are virtual, like all methods in Java. This can sometimes lead to surprising results. Given the declarations

    interface A {
        default void m() { System.out.println("hello from A"); }
    }
    interface B extends A {
        default void m() { System.out.println("hello from B"); }
    }
    interface C extends A {}
    class D implements B, C {}
the code

    C c = new D();
    c.m();
will print hello from B. The static type of c is unimportant; what counts is that it is an instance of D, whose most specific version of m is inherited from B.




############################################################

#########  What Does Singleton Mean? (design pattern)

In software engineering, the singleton pattern is a software design pattern that restricts the instantiation of a class to one "single" instance. This is useful when exactly one object is needed to coordinate actions across the system.


In Java the Singleton pattern will ensure that there is only one instance of a class is created in the Java Virtual Machine. It is used to provide global point of access to the object. In terms of practical use Singleton patterns are used in 

logging, caches, thread pools, configuration settings, device driver objects.


############################################################

###### What is static keyword in java?

In the Java programming language, the keyword static indicates that the particular member belongs to a type itself, rather than to an instance of that type. This means that only one instance of that static member is created which is shared across all instances of the class.

user for :

Static methods in java belong to the class (not an instance of it). They use no instance variables and will usually take input from the parameters, perform actions on it, then return some result. Instances methods are associated with objects and, as the name implies, can use instance variables


static is a non-access modifier in Java which is applicable for the following:

blocks
variables
methods
nested classes
To create a static member(block,variable,method,nested class), precede its declaration with the keyword static. When a member is declared static, it can be accessed before any objects of its class are created, and without reference to any object. For example, in below java program, we are accessing static method m1() without creating any object of Test class.

filter_none
edit
play_arrow

brightness_4
// Java program to demonstrate that a static member 
// can be accessed before instantiating a class 
class Test 
{ 
    // static method 
    static void m1() 
    { 
        System.out.println("from m1"); 
    } 
  
    public static void main(String[] args) 
    { 
          // calling m1 without creating 
          // any object of class Test 
           m1(); 
    } 
} 
Output:



from m1
Static blocks

If you need to do computation in order to initialize your static variables, you can declare a static block that gets executed exactly once, when the class is first loaded. Consider the following java program demonstrating use of static blocks.

filter_none
edit
play_arrow

brightness_4
// Java program to demonstrate use of static blocks 
class Test 
{ 
    // static variable 
    static int a = 10; 
    static int b; 
      
    // static block 
    static { 
        System.out.println("Static block initialized."); 
        b = a * 4; 
    } 
  
    public static void main(String[] args) 
    { 
       System.out.println("from main"); 
       System.out.println("Value of a : "+a); 
       System.out.println("Value of b : "+b); 
    } 
} 
Output:

Static block initialized.
from main
Value of a : 10
Value of b : 40
For Detailed article on static blocks, see static blocks

############################################################

What is multithreading in java and how we can implement it ?

Multithreading is a Java feature that allows concurrent execution of two or more parts of a program for maximum utilization of CPU. Each part of such program is called a thread. So, threads are light-weight processes within a process. Threads can be created by using two mechanisms

1. Extending the Thread class
2. Implementing the Runnable Interface

 
Thread creation by extending the Thread class

We create a class that extends the java.lang.Thread class. This class overrides the run() method available in the Thread class. A thread begins its life inside run() method. We create an object of our new class and call start() method to start the execution of a thread. Start() invokes the run() method on the Thread object.



filter_none
edit
play_arrow

brightness_4
// Java code for thread creation by extending 
// the Thread class 
class MultithreadingDemo extends Thread 
{ 
    public void run() 
    { 
        try
        { 
            // Displaying the thread that is running 
            System.out.println ("Thread " + 
                  Thread.currentThread().getId() + 
                  " is running"); 
  
        } 
        catch (Exception e) 
        { 
            // Throwing an exception 
            System.out.println ("Exception is caught"); 
        } 
    } 
} 
  
// Main Class 
public class Multithread 
{ 
    public static void main(String[] args) 
    { 
        int n = 8; // Number of threads 
        for (int i=0; i<8; i++) 
        { 
            MultithreadingDemo object = new MultithreadingDemo(); 
            object.start(); 
        } 
    } 
} 
Output :

Thread 8 is running
Thread 9 is running
Thread 10 is running
Thread 11 is running
Thread 12 is running
Thread 13 is running
Thread 14 is running
Thread 15 is running
 
Thread creation by implementing the Runnable Interface

We create a new class which implements java.lang.Runnable interface and override run() method. Then we instantiate a Thread object and call start() method on this object.

filter_none
edit
play_arrow

brightness_4
// Java code for thread creation by implementing 
// the Runnable Interface 
class MultithreadingDemo implements Runnable 
{ 
    public void run() 
    { 
        try
        { 
            // Displaying the thread that is running 
            System.out.println ("Thread " + 
                                Thread.currentThread().getId() + 
                                " is running"); 
  
        } 
        catch (Exception e) 
        { 
            // Throwing an exception 
            System.out.println ("Exception is caught"); 
        } 
    } 
} 
  
// Main Class 
class Multithread 
{ 
    public static void main(String[] args) 
    { 
        int n = 8; // Number of threads 
        for (int i=0; i<n; i++) 
        { 
            Thread object = new Thread(new MultithreadingDemo()); 
            object.start(); 
        } 
    } 
} 
Output :

Thread 8 is running
Thread 9 is running
Thread 10 is running
Thread 11 is running
Thread 12 is running
Thread 13 is running
Thread 14 is running
Thread 15 is running
 

Thread Class vs Runnable Interface

1. If we extend the Thread class, our class cannot extend any other class because Java doesn’t support multiple inheritance. But, if we implement the Runnable interface, our class can still extend other base classes.

2. We can achieve basic functionality of a thread by extending Thread class because it provides some inbuilt methods like yield(), interrupt() etc. that are not available in Runnable interface.

 
This article is contributed by Mehak Narang. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above

############################################################


############Checked vs Unchecked Exceptions in Java


In Java, there are two types of exceptions:

1) Checked: are the exceptions that are checked at compile time. If some code within a method throws a checked exception, then the method must either handle the exception or it must specify the exception using throws keyword.

For example, consider the following Java program that opens file at location “C:\test\a.txt” and prints the first three lines of it. The program doesn’t compile, because the function main() uses FileReader() and FileReader() throws a checked exception FileNotFoundException. It also uses readLine() and close() methods, and these methods also throw checked exception IOException



filter_none
edit
play_arrow

brightness_4
import java.io.*; 
  
class Main { 
    public static void main(String[] args) { 
        FileReader file = new FileReader("C:\\test\\a.txt"); 
        BufferedReader fileInput = new BufferedReader(file); 
          
        // Print first 3 lines of file "C:\test\a.txt" 
        for (int counter = 0; counter < 3; counter++)  
            System.out.println(fileInput.readLine()); 
          
        fileInput.close(); 
    } 
} 
Output:

Exception in thread "main" java.lang.RuntimeException: Uncompilable source code - 
unreported exception java.io.FileNotFoundException; must be caught or declared to be 
thrown
    at Main.main(Main.java:5)
To fix the above program, we either need to specify list of exceptions using throws, or we need to use try-catch block. We have used throws in the below program. Since FileNotFoundException is a subclass of IOException, we can just specify IOException in the throws list and make the above program compiler-error-free.

filter_none
edit
play_arrow

brightness_4
import java.io.*; 
  
class Main { 
    public static void main(String[] args) throws IOException { 
        FileReader file = new FileReader("C:\\test\\a.txt"); 
        BufferedReader fileInput = new BufferedReader(file); 
          
        // Print first 3 lines of file "C:\test\a.txt" 
        for (int counter = 0; counter < 3; counter++)  
            System.out.println(fileInput.readLine()); 
          
        fileInput.close(); 
    } 
} 
Output: First three lines of file “C:\test\a.txt”

2) Unchecked are the exceptions that are not checked at compiled time. In C++, all exceptions are unchecked, so it is not forced by the compiler to either handle or specify the exception. It is up to the programmers to be civilized, and specify or catch the exceptions.
In Java exceptions under Error and RuntimeException classes are unchecked exceptions, everything else under throwable is checked.

                   +-----------+
           | Throwable |
                   +-----------+
                    /         \
           /           \
          +-------+          +-----------+
          | Error |          | Exception |
          +-------+          +-----------+
       /  |  \           / |        \
         \________/      \______/         \
                            +------------------+
    unchecked     checked    | RuntimeException |
                    +------------------+
                      /   |    |      \
                     \_________________/
                       
                       unchecked
Consider the following Java program. It compiles fine, but it throws ArithmeticException when run. The compiler allows it to compile, because ArithmeticException is an unchecked exception.

filter_none
edit
play_arrow

brightness_4
class Main { 
   public static void main(String args[]) { 
      int x = 0; 
      int y = 10; 
      int z = y/x; 
  } 
} 
Output:

Exception in thread "main" java.lang.ArithmeticException: / by zero
    at Main.main(Main.java:5)
Java Result: 1

############################################################


####### .  What is Hash map and how it work


How HashMap works in Java

HashMap works on the principle of Hashing .  To understand Hashing , we should understand the three terms first   i.e  Hash Function , Hash Value and Bucket .

What is Hash Function , Hash Value  and Bucket ?

hashCode() function  which returns an integer value is the Hash function. The important point to note that ,  this method is present in Object class ( Mother of all class ) .

This is the code for the hash function(also known as hashCode method) in Object Class :

    public native int hashCode();

The most important point to note from the above line :  hashCode method return  int value .
So the Hash value is the int value returned by the hash function .


    So summarize the terms in the diagram below :
                  


how hash  map works in java 


What is bucket ?
A bucket is used to store key value pairs . A bucket can have multiple key-value pairs . In hash map, bucket used simple linked list to store objects .


After understanding the terms we are ready to move next step , How HashMap works in java or How get() works internally in java .


Code inside Java Api (HashMap class internal implementation) for HashMap get(Obejct key) method

1.  Public  V get(Object key)
   {
2.     if (key ==null)
3.     //Some code
    
4.     int hash = hash(key.hashCode());
    
5.     // if key found in hash table then  return value
6.     //    else return null
   }

Hash map works on the principle of hashing 

HashMap get(Key k) method calls hashCode method on the key object and applies returned hashValue to its own static hash function to find a bucket location(backing array) where keys and values are stored in form of a nested class called Entry (Map.Entry) . So you have concluded that from the previous line that Both key and value is stored in the bucket as a form of  Entry object . So thinking that Only value is stored  in the bucket is not correct and will not give a good impression on the interviewer .

* Whenever we call get( Key k )  method on the HashMap object . First it checks that whether key is null or not .  Note that there can only be one null key in HashMap .  

If key is null , then Null keys always map to hash 0, thus index 0.

If key is not null then , it will call hashfunction on the key object , see line 4 in above method i.e. key.hashCode()  ,so after key.hashCode() returns hashValue , line 4 looks like

4.                int hash = hash(hashValue)

 , and now ,it applies returned hashValue into its own hashing function .

We might wonder why we are calculating the hashvalue again using hash(hashValue). Answer is ,It defends against poor quality hash functions.

Now step 4 final  hashvalue is used to find the bucket location at which the Entry object is stored . Entry object stores in the bucket like this (hash,key,value,bucketindex) .  

Interviewer:    What if  when two different keys have the same hashcode ?

Solution, equals() method comes to rescue.Here candidate gets puzzled. Since bucket is one and we have two objects with the same hashcode .Candidate usually forgets that bucket is a simple linked list.

The bucket is the linked list effectively . Its not a LinkedList as in a java.util.LinkedList - It's a separate (simpler) implementation just for the map .

So we traverse through linked list , comparing keys in each entries using keys.equals() until it return true.  Then the corresponding entry object Value is returned .


how hashmap works internally in java







One of  our readers Jammy  asked a very good  question 

When the functions 'equals' traverses through the linked list does it traverses from start to end one by one...in other words brute method. Or the linked list is sorted based on key and then it traverses?

Answer is when an element is added/retrieved, same procedure follows:


a. Using key.hashCode() [ see above step 4],determine initial hashvalue for the key

b. Pass intial hashvalue as hashValue  in    hash(hashValue) function, to calculate the final hashvalue.

c. Final hash value is then passed as a first parameter in the indexFor(int ,int )method .
    The second parameter is length which is a constant in HashMap Java Api , represented by                             DEFAULT_INITIAL_CAPACITY

    The default  value of DEFAULT_INITIAL_CAPACITY is 16 in HashMap Java Api .

 indexFor(int,int) method  returns the first entry in the appropriate bucket. The linked list in the bucket is then iterated over - (the end is found and the element is added or the key is matched and the value is returned )


Explanation about indexFor(int,int) is below :

/**
* Returns index for hash code h.
*/
static int indexFor(int h, int length) {
    return h & (length-1);
}


The above function indexFor() works because Java HashMaps always have a capacity, i.e. number of buckets, as a power of 2.
 Let's work with a capacity of 256,which is 0x100, but it could work with any power of 2. Subtracting 1
from a power of 2 yields the exact bit mask needed to bitwise-and with the hash to get the proper bucket index, of range 0 to length - 1.
256 - 1 = 255
0x100 - 0x1 = 0xFF
E.g. a hash of 257 (0x101) gets bitwise-anded with 0xFF to yield a bucket number of 1.



#### Interviewer:    What if  when two  keys are same and have the same hashcode ?
If key needs to be inserted and already inserted hashkey's hashcodes are same, and keys are also same(via reference or using equals() method)  then override the previous key value pair with the current key value pair.

##### The other important point to note is that in Map ,Any class(String etc.) can serve as a key if and only if it overrides the equals() and hashCode() method .


##### Interviewer:  How will you measure the performance of HashMap?

According to Oracle Java docs,  

An instance of HashMap has two parameters that affect its performance: initial capacity and load factor. 

The capacity is the number of buckets in the hash table( HashMap class is roughly equivalent to Hashtable, except that it is unsynchronized and permits nulls.), and the initial capacity is simply the capacity at the time the hash table is created. 


The load factor is a measure of how full the hash table is allowed to get before its capacity is automatically increased. When the number of entries in the hash table exceeds the product of the load factor and the current capacity, the hash table is rehashed (that is, internal data structures are rebuilt) so that the hash table has approximately twice the number of buckets.

In HashMap class, the default value of load factor is (.75) .

Interviewer : What is the time complexity of Hashmap get() and put() method ?

The hashmap implementation provides constant time performance for (get and put) basic operations
i.e the complexity of get() and put() is O(1) , assuming the hash function disperses the elements properly among the buckets. 

Interviewer : What is the difference between HashMap and ConcurrentHashMap ?

It is also one of the popular interview question on HashMap , you can find the answer here
HashMap vs ConcurrentHashMap

How HashMap works in Java 8  
In java 8 there is a lot of changes in the inner representation of HashMap. The implementation of HashMap went from 1k lines of code in java 7 to 2k lines of code in java 8. In java 8, Node class contains the exact same information as the Entry class i.e Node class contains ( hash , key, value, bucketindex).
Here is the implementation of the Node class in java 8.

static class Node<K,V> implements Map.Entry<K,V> {

        final int hash;
        final K key;
        V value;
        Node<K,V> next;

        Node(int hash, K key, V value, Node<K,V> next) {
            this.hash = hash;
            this.key = key;
            this.value = value;
            this.next = next;
        }

What’s the big difference from java 7 ?

TreeNode class extends Node through LInkedHashMap.Entry<K,V>. In other words ,
TreeNode indirectly extends Node class. A TreeNode internally implements Red-Black tree structure. It stores more information than Node class so that it can perform get(),add() or delete() operations in O(log(n)). As we know Node class contains (hash,key,value,bucketindex) where as TreeNode class contains following list of data.

static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {

        TreeNode<K,V> parent;  // red-black tree links
        TreeNode<K,V> left;
        TreeNode<K,V> right;
        TreeNode<K,V> prev;    // needed to unlink next upon deletion
        boolean red;

        TreeNode(int hash, K key, V val, Node<K,V> next) {
            super(hash, key, val, next);
        }

What are Red Black Trees and Why they are used?

According to Wikipedia,
Red-Black trees are self-balancing binary search trees. Red-black tree makes sure that the length of the binary search trees is always log(n) despite new addition or removal of nodes. The main advantage of using Red-black tree structure is in a case where many entries are in the same bucket. For search operation,in java 7,it will take O(n) with a linked list. While in java 8 , the same search operation in a tree will cost O(log(n)).

Drawbacks : Tree really takes more space than the linked list.

By Inheritance, bucket can contain both Node(Entry object) and TreeNode(Red-black tree).

Oracle java developers decided to use both data structures and following rules are applied.

1. If for a given bucket , there are more than 8 Nodes, the linked list is converted into a
red-black tree. This is represented by the following code in HashMap class :

static final int TREEIFY_THRESHOLD = 8;

2. If for a given bucket , there are less than 6 nodes, then the tree can be converted
into a linkedlist.

static final int UNTREEIFY_THRESHOLD = 6;


The below Java 8 HashMap image shows both trees(at bucket 0) and linkedlists (at bucket 1,2 and 3). Bucket 0 is a Tree because it contains at least 8 nodes.

Tree and LinkedList together in a Bucket in HashMap




Performance Issue in Java 8

In the best case scenario, put() and get() operations have a O(1) time complexity. But if you do not provide efficient hash function of the key , then you might end up with very slow get() and put() operations.

The good performance of the get() and put() operations depend on the repartition of the data into the different indexes of the bucket.
If the hash function of your key is poorly designed, then you will have a skew repartition (capacity of the bucket becomes irrelevant). All the get() and put() operations that use the biggest linked lists of entry will be really slow. It is due to the reason as the get() and put() operation need to iterate the entire lists. In the worst case scenario (when hash function of the key is poorly designed and all the entry objects are in the same buckets), you would end up with O(n) time complexity.

Below are the images showing skewed HashMap and well balanced HashMap. In the case of skewed HashMap . the put() and get() operations on the bucket 0 are costlier. Getting the Entry F will cost 5 iterations.



############################################################

# Caching 

Caching in distributed systems is an important aspect for designing scalable systems. We first discuss what is a cache and why we use it. We then talk about what are the key features of a cache in a distributed system.

The cache management policies of LRU and Sliding Window are mentioned here. For high performance, the cache eviction policy must be chosen carefully. To keep data consistent and memory footprint low, we must choose a write through or write back consistency policy.

Cache management is important because of its relation to cache hit ratios and performance. We talk about various scenarios in a distributed environment.

AlgoExpert: 
http://www.algoexpert.io/gaurav

Made by engineers from Google and Uber, this site helps you build your algorithmic skills using code and white board explanations.
Be sure to use the code ' for the discount. You get 15% off! 


- to reduce network traffic
- reduce load on DB
- Faster retrival


Caching - purging/cleaisng:- Eviction policy

 cache management policies of LRU and Sliding Window are mentioned here. For high performance, the cache eviction policy must be chosen carefully

- LRU - least recently used 

- LFU - Least recently used 

- Sliding window 

Caching - Consistency issue :

To keep data consistent and memory footprint low, we must choose a write through or write back consistency policy.

Data is cached on the server side but an update is made in the data base , how is cache updated? 
- Write through 

      data update is made to the data in cache and then an update is made on the DB , ISSUES  - what if this data is present
      as cache in multiple servers , so write through will not work in this case
      write through , you can do bulk updates updates at once by just updating the cache first and then doing the DB operations all at once
      
- Write back 
     We have to update the one source of truht and we have to keep updating the entires in cache, and thrash the old value in 
     cache ,but this is slow


############################################################

Nosql

NoSQL is a popular database storage method. It keeps data as key value pairs. The advantages and disadvantages of NoSQL compared with RDBMS (which uses SQL) are discussed here, using the Cassandra architecture as an example.

We talk about sharding, redundancy, load balancing, compaction and some other features in NoSQL databases. This allows them to scale efficiently.

- data is inserted and retrieved as a whole block of json at once, all data is contented in one block 
- No schema / schema is easily changeblae, schema is flexible , new attribute added in RDMS you will have to add new column to SQL [put locks on 
table and then update] , wiht nosql you can just add the field directly to the json block 
- Built for scale[Sharding - horizontal scaling]

Sharding is a database architecture pattern related to horizontal partitioning — the practice of separating one table's rows into multiple different tables, known as partitions. Each partition has the same schema and columns, but also entirely different rows

- built for metrics, aggregations , analysis

Cons:
- ACID not guarnteee , hence fina
- Not read optimized 
- relations are not implicit
- joins are hard [all are manual , no intelligence as they are in json form ]


############################################################



############################################################


############################################################


############################################################


############################################################


############################################################
